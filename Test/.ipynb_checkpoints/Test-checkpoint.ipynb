{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d11f4fa-136f-4323-b426-7cca10c5ec0f",
   "metadata": {},
   "source": [
    "#### Laod Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac671a67-9e92-480f-bcc5-bf06b2b969da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import importlib\n",
    "import matplotlib\n",
    "# Get the absolute path of the parent directory\n",
    "project_path = os.path.abspath(\"..\")  \n",
    "sys.path.append(project_path)\n",
    "matplotlib.rcParams.update(matplotlib.rcParamsDefault)\n",
    "\n",
    "import MEAL\n",
    "import MEAL.builder_block as BD\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import MEAL.builder_block as BD\n",
    "import MEAL.without_augmentation as NA\n",
    "import MEAL.traditional_augmentation as TA\n",
    "import MEAL.fusion_layer as FL\n",
    "import MEAL.encoder_concatenation as CC\n",
    "import MEAL.processing as pr\n",
    "from MEAL.builder_block import (\n",
    "    FlipAugmentation, RotateAugmentation, CropAugmentation, IntensityAugmentation\n",
    ")\n",
    "import MEAL.processing as pr\n",
    "\n",
    "import unittest\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204c291b-98bc-4700-8b31-9942c2489f70",
   "metadata": {},
   "source": [
    "#### Without Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b56b303-da0e-4648-90f8-bd908bf9d0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_dataset_loading (__main__.TestComponents.test_dataset_loading) ... ok\n",
      "test_model_building (__main__.TestComponents.test_model_building) ... ok\n",
      "test_residual_block_output_shape (__main__.TestComponents.test_residual_block_output_shape) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.847s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "class TestComponents(unittest.TestCase):\n",
    "\n",
    "    def setUp(self):\n",
    "        self.input_shape = (128, 128, 64, 1)\n",
    "        self.batch_size = 1\n",
    "\n",
    "    def test_model_building(self):\n",
    "        model = NA.refined_diffusion_model(self.input_shape)\n",
    "        self.assertIsInstance(model, tf.keras.Model)\n",
    "        self.assertEqual(model.output_shape, (None, 128, 128, 64, 1))\n",
    "\n",
    "    def test_residual_block_output_shape(self):\n",
    "        x = tf.random.normal((1, 64, 64, 32, 64))\n",
    "        out = pr.refined_residual_block(x, 64)\n",
    "        self.assertEqual(out.shape, x.shape)\n",
    "\n",
    "    def test_dataset_loading(self):\n",
    "        dummy_path = \"tests/dummy_data\"\n",
    "        os.makedirs(os.path.join(dummy_path, \"input\"), exist_ok=True)\n",
    "        os.makedirs(os.path.join(dummy_path, \"target\"), exist_ok=True)\n",
    "        \n",
    "        # Create dummy .npy files\n",
    "        for i in range(2):\n",
    "            np.save(os.path.join(dummy_path, \"input\", f\"{i}.npy\"), np.random.rand(*self.input_shape))\n",
    "            np.save(os.path.join(dummy_path, \"target\", f\"{i}.npy\"), np.random.rand(*self.input_shape[:3]))\n",
    "\n",
    "        dataset = pr.create_dataset(\n",
    "            os.path.join(dummy_path, \"input\"),\n",
    "            os.path.join(dummy_path, \"target\"),\n",
    "            self.input_shape,\n",
    "            self.input_shape[:3],\n",
    "            self.batch_size,\n",
    "            shuffle=False\n",
    "        )\n",
    "        self.assertIsInstance(dataset, tf.data.Dataset)\n",
    "        for x, y in dataset.take(1):\n",
    "            self.assertEqual(x.shape, (1, 128, 128, 64, 1))\n",
    "            self.assertEqual(y.shape, (1, 128, 128, 64))\n",
    "\n",
    "    def tearDown(self):\n",
    "        import shutil\n",
    "        shutil.rmtree(\"tests/dummy_data\", ignore_errors=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    unittest.TextTestRunner(verbosity=2).run(unittest.TestLoader().loadTestsFromTestCase(TestComponents))\n",
    "\n",
    "    # unittest.main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9bd1326-5b82-4695-b224-5a0fcd273a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "## integration test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef06286a-f5b0-4234-b1b3-00689231c6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 99.701s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "class TestPipelineIntegration(unittest.TestCase):\n",
    "\n",
    "    def setUp(self):\n",
    "        self.input_shape = (128, 128, 64, 1)\n",
    "        self.target_shape = self.input_shape[:3]\n",
    "        self.batch_size = 1\n",
    "\n",
    "        # Generate dummy training data (1 sample only)\n",
    "        x = np.random.rand(*self.input_shape).astype(np.float32)\n",
    "        y = np.random.rand(*self.target_shape).astype(np.float32)\n",
    "\n",
    "        self.train_ds = tf.data.Dataset.from_tensor_slices((x[np.newaxis, ...], y[np.newaxis, ...]))\n",
    "        self.train_ds = self.train_ds.batch(self.batch_size)\n",
    "\n",
    "    def test_model_training_pipeline(self):\n",
    "        model = NA.refined_diffusion_model(self.input_shape)\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "            loss=pr.combined_loss,\n",
    "            metrics=['mae']\n",
    "        )\n",
    "\n",
    "        # Only run for 1 epoch on dummy data\n",
    "        history = model.fit(\n",
    "            self.train_ds,\n",
    "            epochs=2,\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        # Check training history exists\n",
    "        self.assertTrue(\"loss\" in history.history)\n",
    "        self.assertGreater(len(history.history['loss']), 0)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    unittest.TextTestRunner().run(unittest.TestLoader().loadTestsFromTestCase(TestPipelineIntegration))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2450b530-5ecf-40a4-aee9-0412a1de6540",
   "metadata": {},
   "source": [
    "#### Traditional Augmentation (TA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f53bdb2-27ad-467f-8364-dea855dadf02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_crop_layer (__main__.TestTraditionalAugmentation.test_crop_layer) ... ok\n",
      "test_flip_layer (__main__.TestTraditionalAugmentation.test_flip_layer) ... ok\n",
      "test_intensity_layer (__main__.TestTraditionalAugmentation.test_intensity_layer) ... ok\n",
      "test_model_creation (__main__.TestTraditionalAugmentation.test_model_creation) ... ok\n",
      "test_rotate_layer (__main__.TestTraditionalAugmentation.test_rotate_layer) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.265s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "class TestTraditionalAugmentation(unittest.TestCase):\n",
    "    \n",
    "    def setUp(self):\n",
    "        self.input_shape = (128, 128, 64, 1)\n",
    "        self.batch_size = 1\n",
    "        self.sample_input = tf.random.normal((1, *self.input_shape))\n",
    "\n",
    "    def test_flip_layer(self):\n",
    "        layer = TA.FlipAugmentation()\n",
    "        output = layer(self.sample_input)\n",
    "        self.assertEqual(output.shape, self.sample_input.shape)\n",
    "\n",
    "    def test_rotate_layer(self):\n",
    "        layer = TA.RotateAugmentation(axis=(1, 2))\n",
    "        output = layer(self.sample_input)\n",
    "        self.assertEqual(output.shape, self.sample_input.shape)\n",
    "\n",
    "    def test_crop_layer(self):\n",
    "        layer = TA.CropAugmentation()\n",
    "        output = layer(self.sample_input)\n",
    "    \n",
    "        # Extract shape\n",
    "        b, h, w, d, c = output.shape\n",
    "        self.assertEqual(b, 1)\n",
    "        self.assertEqual(h, 128)\n",
    "        self.assertEqual(w, 128)\n",
    "        self.assertTrue(d <= 64)  # depth can be cropped\n",
    "        self.assertEqual(c, 1)\n",
    "\n",
    "    def test_intensity_layer(self):\n",
    "        layer = TA.IntensityAugmentation()\n",
    "        output = layer(self.sample_input)\n",
    "        self.assertEqual(output.shape, self.sample_input.shape)\n",
    "\n",
    "    def test_model_creation(self):\n",
    "        model = TA.refined_diffusion_model(self.input_shape)\n",
    "        self.assertIsInstance(model, tf.keras.Model)\n",
    "        self.assertEqual(model.output_shape, (None, 128, 128, 64, 1))\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    unittest.TextTestRunner(verbosity=2).run(unittest.TestLoader().loadTestsFromTestCase(TestTraditionalAugmentation))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4411a24f-4fef-45a1-857f-4d7c692dd62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### integration test for TA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4913b44-2b35-4a11-8de0-962d01953f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_model_training (__main__.TestTAPipelineIntegration.test_model_training) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 43.942s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "class TestTAPipelineIntegration(unittest.TestCase):\n",
    "\n",
    "    def setUp(self):\n",
    "        self.input_shape = (128, 128, 64, 1)\n",
    "        self.target_shape = self.input_shape[:3]\n",
    "        self.batch_size = 1\n",
    "        \n",
    "        # Simulated data\n",
    "        x = np.random.rand(*self.input_shape).astype(np.float32)\n",
    "        y = np.random.rand(*self.target_shape).astype(np.float32)\n",
    "\n",
    "        # Expand to batch and wrap as tf.data.Dataset\n",
    "        self.train_ds = tf.data.Dataset.from_tensor_slices((x[np.newaxis, ...], y[np.newaxis, ...]))\n",
    "        self.train_ds = self.train_ds.batch(self.batch_size)\n",
    "        self.train_ds = self.train_ds.map(lambda x, y: (TA.IntensityAugmentation()(x), y))\n",
    "\n",
    "    def test_model_training(self):\n",
    "        model = TA.refined_diffusion_model(self.input_shape)\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "            loss=pr.combined_loss,\n",
    "            metrics=['mae']\n",
    "        )\n",
    "\n",
    "        history = model.fit(self.train_ds, epochs=1, verbose=0)\n",
    "        self.assertTrue(\"loss\" in history.history)\n",
    "        self.assertGreater(len(history.history[\"loss\"]), 0)\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    unittest.TextTestRunner(verbosity=2).run(unittest.TestLoader().loadTestsFromTestCase(TestTAPipelineIntegration))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9178663-1515-41b9-880b-39334d85efb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "adbc798b-89ec-41cd-b8a0-109f3d23a53b",
   "metadata": {},
   "source": [
    "#### Encoder Concatenation (CC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bcc26a3c-c858-46a2-8f45-dc3788117f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_crop_aug (__main__.TestEncoderConcatenation.test_crop_aug) ... ok\n",
      "test_flip_aug (__main__.TestEncoderConcatenation.test_flip_aug) ... ok\n",
      "test_intensity_aug (__main__.TestEncoderConcatenation.test_intensity_aug) ... ok\n",
      "test_model_build (__main__.TestEncoderConcatenation.test_model_build) ... ok\n",
      "test_rotate_aug (__main__.TestEncoderConcatenation.test_rotate_aug) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.371s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "class TestEncoderConcatenation(unittest.TestCase):\n",
    "\n",
    "    def setUp(self):\n",
    "        self.input_shape = (128, 128, 64, 1)\n",
    "        self.sample = tf.random.normal((1, *self.input_shape))\n",
    "\n",
    "    def test_flip_aug(self):\n",
    "        layer = CC.FlipAugmentation()\n",
    "        out = layer(self.sample)\n",
    "        self.assertEqual(out.shape, self.sample.shape)\n",
    "\n",
    "    def test_rotate_aug(self):\n",
    "        layer = CC.RotateAugmentation()\n",
    "        out = layer(self.sample)\n",
    "        self.assertEqual(out.shape, self.sample.shape)\n",
    "\n",
    "    def test_crop_aug(self):\n",
    "        crop_size = (96, 96, 48, 1)  # reduced depth on purpose\n",
    "        layer = CC.CropAugmentation(\n",
    "            crop_size=crop_size,\n",
    "            original_size=self.input_shape[:3] + (1,)\n",
    "        )\n",
    "        out = layer(self.sample)\n",
    "\n",
    "        # Check that height and width are restored, and depth is <= original\n",
    "        self.assertEqual(out.shape[1], 128)  # height\n",
    "        self.assertEqual(out.shape[2], 128)  # width\n",
    "        self.assertLessEqual(out.shape[3], 64)  # depth should be â‰¤ original\n",
    "        self.assertEqual(out.shape[4], 1)  # channel\n",
    "\n",
    "\n",
    "    def test_intensity_aug(self):\n",
    "        layer = CC.IntensityAugmentation()\n",
    "        out = layer(self.sample)\n",
    "        self.assertEqual(out.shape, self.sample.shape)\n",
    "\n",
    "    def test_model_build(self):\n",
    "        model = CC.build_multistream_model(self.input_shape)\n",
    "        self.assertIsInstance(model, tf.keras.Model)\n",
    "        self.assertEqual(len(model.inputs), 4)\n",
    "        self.assertEqual(model.output_shape, (None, 128, 128, 64, 1))\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    unittest.TextTestRunner(verbosity=2).run(unittest.TestLoader().loadTestsFromTestCase(TestEncoderConcatenation))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3347712c-9e53-4c44-81cf-407c90271069",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### CC's integration test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23734073-90ea-4d1c-991f-5cb6b2042939",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_model_training_step (__main__.TestCCPipelineIntegration.test_model_training_step) ... C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\models\\functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['flip_stream', 'rotate_stream', 'crop_stream', 'intensity_stream']. Received: the structure of inputs=('*', '*', '*', '*')\n",
      "  warnings.warn(\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 163.190s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "class TestCCPipelineIntegration(unittest.TestCase):\n",
    "\n",
    "    def setUp(self):\n",
    "        self.input_shape = (128, 128, 64, 1)\n",
    "        self.target_shape = self.input_shape[:3]\n",
    "\n",
    "        # Simulate input streams\n",
    "        x = tf.random.normal((1, *self.input_shape))\n",
    "        y = tf.random.normal((1, *self.target_shape))\n",
    "\n",
    "        self.train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "            ((x, x, x, x), y)\n",
    "        ).batch(1)\n",
    "\n",
    "    def test_model_training_step(self):\n",
    "        model = CC.build_multistream_model(self.input_shape)\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "            loss=pr.combined_loss,\n",
    "            metrics=['mae']\n",
    "        )\n",
    "\n",
    "        history = model.fit(self.train_ds, epochs=1, verbose=0)\n",
    "        self.assertIn(\"loss\", history.history)\n",
    "        self.assertGreater(len(history.history[\"loss\"]), 0)\n",
    "if __name__ == \"__main__\":\n",
    "    unittest.TextTestRunner(verbosity=2).run(unittest.TestLoader().loadTestsFromTestCase(TestCCPipelineIntegration))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8615643b-2565-4ae7-bb39-01862319daf3",
   "metadata": {},
   "source": [
    "#### Builder Block (BD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35591767-b3dc-43ad-94b5-7bc4c0251335",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### unittest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24f6dc12-4bda-450d-be1d-9415c60c1067",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_crop_augmentation (__main__.TestBuilderBlockComponents.test_crop_augmentation) ... ok\n",
      "test_flip_augmentation (__main__.TestBuilderBlockComponents.test_flip_augmentation) ... ok\n",
      "test_intensity_augmentation (__main__.TestBuilderBlockComponents.test_intensity_augmentation) ... ok\n",
      "test_model_building (__main__.TestBuilderBlockComponents.test_model_building) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:204: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "test_rotate_augmentation (__main__.TestBuilderBlockComponents.test_rotate_augmentation) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 9.400s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "class TestBuilderBlockComponents(unittest.TestCase):\n",
    "\n",
    "    def setUp(self):\n",
    "        self.input_shape = (128, 128, 64, 1)\n",
    "        self.sample_input = tf.random.normal((1, *self.input_shape))\n",
    "\n",
    "    def test_flip_augmentation(self):\n",
    "        layer = BD.FlipAugmentation()\n",
    "        output = layer(self.sample_input)\n",
    "        self.assertEqual(output.shape, self.sample_input.shape)\n",
    "\n",
    "    def test_rotate_augmentation(self):\n",
    "        layer = BD.RotateAugmentation()\n",
    "        output = layer(self.sample_input)\n",
    "        self.assertEqual(output.shape, self.sample_input.shape)\n",
    "\n",
    "    def test_crop_augmentation(self):\n",
    "        crop_size = (64, 64, 64, 1)\n",
    "        original_size = self.input_shape\n",
    "        layer = BD.CropAugmentation(crop_size, original_size)\n",
    "        output = layer(self.sample_input)\n",
    "        self.assertEqual(output.shape[1:], (128, 128, 64, 1))  # h, w are resized\n",
    "\n",
    "    def test_intensity_augmentation(self):\n",
    "        layer = BD.IntensityAugmentation()\n",
    "        output = layer(self.sample_input)\n",
    "        self.assertEqual(output.shape, self.sample_input.shape)\n",
    "\n",
    "    def test_model_building(self):\n",
    "        model = BD.build_multistream_model(self.input_shape)\n",
    "        self.assertIsInstance(model, tf.keras.Model)\n",
    "        self.assertEqual(model.output_shape, (None, 128, 128, 64, 1))\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    unittest.TextTestRunner(verbosity=2).run(unittest.TestLoader().loadTestsFromTestCase(TestBuilderBlockComponents))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab52a6fe-a634-4c9c-8d7c-16925c552211",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### integration test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c56d9a1-2582-428c-a988-8cd71e15eca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_training_step (__main__.TestBuilderBlockIntegration.test_training_step) ... C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\nn.py:545: UserWarning: You are using a softmax over axis -1 of a tensor of shape (None, 4, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
      "  warnings.warn(\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 288.078s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "class TestBuilderBlockIntegration(unittest.TestCase):\n",
    "\n",
    "    def setUp(self):\n",
    "        self.input_shape = (128, 128, 64, 1)\n",
    "        self.target_shape = self.input_shape[:3]\n",
    "        self.sample_input = tf.random.normal((1, *self.input_shape))\n",
    "        self.sample_target = tf.random.normal((1, *self.target_shape))\n",
    "\n",
    "        self.train_ds = tf.data.Dataset.from_tensor_slices((self.sample_input, self.sample_target))\n",
    "        self.train_ds = self.train_ds.batch(1)\n",
    "\n",
    "    def test_training_step(self):\n",
    "        model = BD.build_multistream_model(self.input_shape)\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "            loss=BD.pr.combined_loss,\n",
    "            metrics=['mae']\n",
    "        )\n",
    "\n",
    "        history = model.fit(self.train_ds, epochs=1, verbose=0)\n",
    "        self.assertIn(\"loss\", history.history)\n",
    "        self.assertGreater(len(history.history[\"loss\"]), 0)\n",
    "if __name__ == \"__main__\":\n",
    "    unittest.TextTestRunner(verbosity=2).run(unittest.TestLoader().loadTestsFromTestCase(TestBuilderBlockIntegration))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68349ca9-d5cb-4111-93e4-3db10e6b54f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
